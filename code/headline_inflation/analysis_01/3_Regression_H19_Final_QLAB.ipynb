{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9015fd4b",
   "metadata": {},
   "source": [
    "# 3. Regression\n",
    "In this notebook we will finally run our regression models. For that purpose, we are importing the necessary libraries and functions from our ```modules``` folder. We are also importing our extracted dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "380ac8c3",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Warnings\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "# Basic Libraries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import requests\n",
    "import seaborn as sns\n",
    "from scipy import stats\n",
    "from scipy.stats import randint\n",
    "from functools import reduce\n",
    "\n",
    "# Statsmodels\n",
    "import statsmodels.api as sm\n",
    "import pmdarima as pmd\n",
    "from pmdarima.arima import auto_arima\n",
    "from statsmodels.tsa.api import VAR\n",
    "from statsmodels.tsa.vector_ar.var_model import VARResults\n",
    "from statsmodels.tsa.statespace.sarimax import SARIMAX\n",
    "from statsmodels.tsa.arima.model import ARIMA\n",
    "from statsmodels.tsa.stattools import adfuller\n",
    "from statsmodels.tsa.seasonal import seasonal_decompose\n",
    "\n",
    "# Machine Learning models\n",
    "import sklearn.model_selection as skm\n",
    "import sklearn.linear_model as skl\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.feature_selection import SelectFromModel\n",
    "from sklearn.ensemble import RandomForestRegressor, RandomForestClassifier\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV, TimeSeriesSplit, RandomizedSearchCV\n",
    "from sklearn.linear_model import Ridge, Lasso, ElasticNet, ElasticNetCV, LinearRegression, LassoLars, Lars\n",
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "from sklearn.metrics import (\n",
    "    mean_absolute_error,\n",
    "    mean_squared_error,\n",
    "    mean_absolute_percentage_error,\n",
    "    median_absolute_error,\n",
    "    r2_score,\n",
    "    precision_score\n",
    "\n",
    ")\n",
    "\n",
    "from xgboost import XGBRegressor\n",
    "from sklearn.svm import SVR\n",
    "# Bayesian Optimizer\n",
    "from skopt import BayesSearchCV\n",
    "from skopt.space import Real, Integer\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33e8288c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# We import our own functions\n",
    "import sys\n",
    "sys.path.append('../../..')  # Move two levels up to the project root\n",
    "from modules.functions import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "867ff30c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv('../../../input/df_raw.csv', parse_dates=['Fecha'], index_col='Fecha')\n",
    "df.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "240c039f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df_lags = pd.read_csv('../../../input/df_lags.csv', parse_dates=['Fecha'], index_col='Fecha')\n",
    "df_lags.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f1358d3-ea58-40c8-bfff-62ccc2c31b2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df[:'2019-12-01']\n",
    "df_lags = df_lags[:'2019-12-01'] "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e5b191b",
   "metadata": {},
   "source": [
    "## 3.1 Benchmark models\n",
    "\n",
    "In the first section, we first run our benchmark econometric models: ```Random Walk (RW)```,  ```Autoregressive Integrated Moving Average (ARIMA)``` and ```Vector Autoregression (VAR)``` processes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d19a5c2c",
   "metadata": {},
   "source": [
    "### 3.1.1 Random Walk (RW)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a501823b-bbce-4f0c-ad02-9a4e44acd833",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "forecast_horizons = [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12]\n",
    "\n",
    "# We define our target variable\n",
    "target = 'CPI'\n",
    "\n",
    "# We only use CPI as Random Walk is an univariate process\n",
    "df_CPI = pd.DataFrame(df_lags.CPI)\n",
    "\n",
    "# We create our train and test set\n",
    "train_set = df_CPI[df_CPI.index < '2019-01-01']\n",
    "test_set  = df_CPI[df_CPI.index >= '2019-01-01']\n",
    "\n",
    "predictions = {}\n",
    "\n",
    "for h in forecast_horizons:\n",
    "    # We get the values h horizons before\n",
    "    predicted_value = train_set.iloc[-1, 0] \n",
    "\n",
    "    # We save it for horizon h\n",
    "    predictions[h] = predicted_value\n",
    "\n",
    "predicted = pd.DataFrame([predictions]).transpose().reset_index()\n",
    "\n",
    "predicted.columns = ['Horizon', 'Prediction']\n",
    "\n",
    "predicted = predicted.set_index(test_set.index)\n",
    "\n",
    "predicted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb796d57",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# We create our results dataframe, concatenating the predicted and the actual values\n",
    "results_rw = pd.concat([predicted, test_set[target]], axis=1)\n",
    "results_rw.rename(columns={'Horizon': 'Horizon', 'Prediction': 'Predicted', 'CPI': 'Actual'}, inplace=True)\n",
    "results_rw"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65a06604",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# We get our metrics using our function\n",
    "RMSE_rw, MAPE_rw = get_metrics(results_rw, 'RW')\n",
    "metrics_rw = pd.concat([RMSE_rw, MAPE_rw], axis = 1)\n",
    "metrics_rw"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1207a96",
   "metadata": {},
   "source": [
    "### 3.1.2 Autoregressive Integrated Moving Average (ARIMA)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b177fcc2",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# We only use CPI as Random Walk is an univariate process\n",
    "df_CPI = pd.DataFrame(df_lags.CPI)\n",
    "\n",
    "# We create our train and test set\n",
    "train_set = df_CPI[df_CPI.index < '2019-01-01']\n",
    "test_set  = df_CPI[df_CPI.index >= '2019-01-01']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83f2a36d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# We find the best SARIMA model\n",
    "autoarima = pmd.auto_arima(\n",
    "        y = train_set,\n",
    "        start_p=1,\n",
    "        start_q=0,\n",
    "        seasonal=True,\n",
    "        max_p=12,\n",
    "        max_d=1,\n",
    "        max_q=6,\n",
    "        max_P=12,\n",
    "        max_D=1,\n",
    "        max_Q=6,\n",
    "        m=4,\n",
    "        n_jobs=-1,\n",
    "        suppress_warnings=True,\n",
    "        )\n",
    "\n",
    "# We indicate the seasonal order for monthly data\n",
    "seasonal_order = (1, 1, 1, 12)\n",
    "\n",
    "# We create our ARIMA model\n",
    "model = SARIMAX(train_set,\n",
    "                order=autoarima.order,\n",
    "                seasonal_order=autoarima.seasonal_order,\n",
    "                enforce_stationarity = False,\n",
    "                enforce_invertibility = False)\n",
    "        \n",
    "# We fit the model\n",
    "model_fit = model.fit()\n",
    "\n",
    "# We forecast for the next 12 horizons\n",
    "forecast_values = model_fit.get_forecast(steps=12)\n",
    "predicted = pd.DataFrame(forecast_values.predicted_mean, index = test_set.index)\n",
    "\n",
    "# We create our results dataframe, concatenating the predicted and the actual values\n",
    "results = pd.concat([predicted, test_set[target]], axis=1)\n",
    "results.rename(columns={'predicted_mean': 'Predicted', 'CPI': 'Actual'}, inplace=True)\n",
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55f0862c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# We get our metrics using our function\n",
    "RMSE_arima, MAPE_arima = get_metrics(results, 'ARIMA')\n",
    "metrics_arima= pd.concat([RMSE_arima, MAPE_arima], axis = 1)\n",
    "metrics_arima"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a990ec7c-b5b6-49a1-9ce9-067c40e8a137",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "rmse_econometrics = pd.concat([RMSE_rw, RMSE_arima], axis=1)\n",
    "\n",
    "rmse_econometrics.plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "318374f2",
   "metadata": {},
   "source": [
    "### 3.1.3 Vector autoregression (VAR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0f74cb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# We define our target variable, as well as our train and test set\n",
    "target = 'CPI'\n",
    "train_set = df[df.index < '2019-01-01']\n",
    "test_set  = df[df.index >= '2019-01-01']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9073c369",
   "metadata": {},
   "outputs": [],
   "source": [
    "# We model our VAR including up to two lags\n",
    "model_var = VAR(df)\n",
    "model_fit = model_var.fit(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1bc63d4-fe04-431f-a516-1a1dc3ab50a4",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Summary of the model\n",
    "# model_fit.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f037addd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# We forecast for the next 12 months\n",
    "preds = model_fit.forecast(df.values[-3:], 12)\n",
    "preds = pd.DataFrame(preds, index = test_set[target].index)[0]\n",
    "\n",
    "# We create our results dataframe, concatenating the predicted and the actual values\n",
    "results_var = pd.concat([preds, test_set[target]],axis=1)\n",
    "results_var.rename(columns={'CPI': 'Actual', 0: 'Predicted'}, inplace=True)\n",
    "results_var"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f901da77",
   "metadata": {},
   "outputs": [],
   "source": [
    "# We get our metrics using our function\n",
    "RMSE_var, MAPE_var = get_metrics(results_var, 'VAR')\n",
    "metrics_var= pd.concat([RMSE_var, MAPE_var], axis = 1)\n",
    "metrics_var"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e262fe99-b2b6-4d5a-a7d9-ca2848939434",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "rmse_econometrics = pd.concat([RMSE_rw, RMSE_arima, RMSE_var], axis=1)\n",
    "\n",
    "rmse_econometrics.plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "535b52ff",
   "metadata": {},
   "source": [
    "## 3.2 Machine learning models\n",
    "\n",
    "In the second section, we run our machine learning models: ```Ridge Regression (Ridge)```,  ```Least Absolute Shrinkage and Selection Operator (LASSO)``` and ```Random Forest (RF)``` models"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d84ddfb-7b8d-4f45-b876-fd5ee34fc7b7",
   "metadata": {},
   "source": [
    "### 3.2.1 Ridge Regression (Ridge)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60d97c19-4658-4b80-836f-543016a9e684",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "target = \"CPI\"\n",
    "Y = pd.DataFrame(df_lags[target])\n",
    "X = df_lags.drop(columns=[target])\n",
    "\n",
    "train_set = df_lags[df_lags.index < '2019-01-01']\n",
    "test_set  = df_lags[df_lags.index >= '2019-01-01']\n",
    "\n",
    "y_train = train_set[target]\n",
    "y_test  = test_set[target]\n",
    "X_train = train_set.loc[:, train_set.columns != target]\n",
    "X_test  = test_set.loc[:, test_set.columns != target]\n",
    "\n",
    "# We define the model\n",
    "tscv = TimeSeriesSplit(n_splits=5, test_size= 12)\n",
    "scaler = StandardScaler()\n",
    "\n",
    "# Define model\n",
    "model = Pipeline([\n",
    "    ('scaler', scaler),\n",
    "    ('regressor', ElasticNet(l1_ratio=0))  \n",
    "])\n",
    "\n",
    "# Define grid search\n",
    "grid_params = {\n",
    "    'regressor__alpha': np.linspace(0.01, 10, 1000) \n",
    "}\n",
    "\n",
    "\n",
    "# We implement the gridsearch\n",
    "grid_search = GridSearchCV( model, grid_params, cv = tscv, scoring = 'neg_mean_squared_error')\n",
    "grid_search.fit( X_train, y_train )\n",
    "grid_search_ridge = pd.DataFrame( grid_search.cv_results_ )\n",
    "\n",
    "ridge_model  = grid_search.best_estimator_\n",
    "ridge_params = grid_search.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93a87f5d-5112-4361-9e6f-9740cb3372fd",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "pred_vars = X_train.columns.to_list()\n",
    "coefficients = ridge_model.named_steps['regressor'].coef_\n",
    "vars_df_ridge      = pd.DataFrame( {'Var': X_train.columns, 'Coefficient': coefficients } )\n",
    "vars_df_ridge      = vars_df_ridge.reindex( vars_df_ridge[ 'Coefficient' ].abs().sort_values( ascending = False ).index )\n",
    "vars_df_ridge.to_excel( f'../../../output/3_Regression/h19_test_final/coef_ridge_h19.xlsx' )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4f81db5-bc8c-415e-b473-4b690ceab81d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "y_pred = ridge_model.predict( X_test )\n",
    "y_pred = pd.Series(y_pred, index = y_test.index)\n",
    "results_ridge = pd.concat([y_pred, y_test],axis=1)\n",
    "results_ridge.rename(columns={'CPI': 'Actual', 0: 'Predicted'}, inplace=True)\n",
    "results_ridge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "539b3a2a-3976-4b1b-8d69-a66946ec6b31",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "RMSE_ridge, MAPE_ridge = get_metrics(results_ridge, 'Ridge')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9019dfb6-d63a-48f8-84e4-9288faa2ebf7",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "pd.concat([RMSE_rw, RMSE_ridge], axis=1).plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23eaa4f1",
   "metadata": {},
   "source": [
    "### 3.2.2 Lasso Regression (Lasso)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50f7ac64",
   "metadata": {},
   "outputs": [],
   "source": [
    "target = \"CPI\"\n",
    "Y = pd.DataFrame(df_lags[target])\n",
    "X = df_lags.drop(columns=[target])\n",
    "\n",
    "train_set = df_lags[df_lags.index < '2019-01-01']\n",
    "test_set  = df_lags[df_lags.index >= '2019-01-01']\n",
    "\n",
    "y_train = train_set[target]\n",
    "y_test  = test_set[target]\n",
    "X_train = train_set.loc[:, train_set.columns != target]\n",
    "X_test  = test_set.loc[:, test_set.columns != target]\n",
    "\n",
    "# We define the model\n",
    "scaler = StandardScaler()\n",
    "\n",
    "# Define model\n",
    "model = Pipeline([\n",
    "    ('scaler', scaler),\n",
    "    ('regressor', ElasticNet(l1_ratio=1))  \n",
    "])\n",
    "\n",
    "# Define grid search\n",
    "grid_params = {\n",
    "    'regressor__alpha': np.linspace(0.01, 10, 1000) \n",
    "}\n",
    "\n",
    "\n",
    "# We implement the gridsearch\n",
    "grid_search = GridSearchCV( model, grid_params, cv = tscv, scoring = 'neg_mean_squared_error')\n",
    "grid_search.fit( X_train, y_train )\n",
    "pd.DataFrame( grid_search.cv_results_ )\n",
    "\n",
    "lasso_model  = grid_search.best_estimator_\n",
    "lasso_params = grid_search.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79d04f06",
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_vars = X_train.columns.to_list()\n",
    "coefficients = lasso_model.named_steps['regressor'].coef_\n",
    "vars_df_lasso      = pd.DataFrame( {'Var': X_train.columns, 'Coefficient': coefficients } )\n",
    "vars_df_lasso      = vars_df_lasso.reindex( vars_df_lasso[ 'Coefficient' ].abs().sort_values( ascending = False ).index )\n",
    "vars_df_lasso.to_excel( f'../../../output/3_Regression/h19_test_final/coef_lasso_h19.xlsx' )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c90c9ea8",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = lasso_model.predict( X_test )\n",
    "y_pred = pd.Series(y_pred, index = y_test.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39b4488c",
   "metadata": {},
   "outputs": [],
   "source": [
    "results_lasso = pd.concat([y_pred, y_test],axis=1)\n",
    "results_lasso.rename(columns={'CPI': 'Actual', 0: 'Predicted'}, inplace=True)\n",
    "results_lasso"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91c13ecf",
   "metadata": {},
   "outputs": [],
   "source": [
    "RMSE_lasso, MAPE_lasso = get_metrics(results_lasso, 'Lasso')\n",
    "pd.concat([RMSE_rw, RMSE_lasso, RMSE_ridge], axis=1).plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1a3d775-c843-47b5-9101-6524fff256a7",
   "metadata": {},
   "source": [
    "### 3.2.3 Elastic Net (EN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d19152f-8836-4f02-a714-1d87500cd31f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "target = \"CPI\"\n",
    "Y = pd.DataFrame(df_lags[target])\n",
    "X = df_lags.drop(columns=[target])\n",
    "\n",
    "train_set = df_lags[df_lags.index < '2019-01-01']\n",
    "test_set  = df_lags[df_lags.index >= '2019-01-01']\n",
    "\n",
    "y_train = train_set[target]\n",
    "y_test  = test_set[target]\n",
    "X_train = train_set.loc[:, train_set.columns != target]\n",
    "X_test  = test_set.loc[:, test_set.columns != target]\n",
    "\n",
    "# We define the model\n",
    "scaler = StandardScaler()\n",
    "\n",
    "# Define model\n",
    "model = Pipeline([\n",
    "    ('scaler', scaler),\n",
    "    ('regressor', ElasticNet(l1_ratio=0.5))  \n",
    "])\n",
    "\n",
    "# Define grid search\n",
    "grid_params_en = {\n",
    "    'regressor__alpha': np.linspace(0.01, 10, 1000),\n",
    "}\n",
    "\n",
    "\n",
    "# We implement the gridsearch\n",
    "grid_search = GridSearchCV( model, grid_params_en, cv = tscv, scoring = 'neg_mean_squared_error')\n",
    "grid_search.fit( X_train, y_train )\n",
    "pd.DataFrame( grid_search.cv_results_ )\n",
    "\n",
    "en_model  = grid_search.best_estimator_\n",
    "en_params = grid_search.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3c1d056-fe30-4beb-a8d0-4a80899e9eaa",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "pred_vars = X_train.columns.to_list()\n",
    "coefficients = en_model.named_steps['regressor'].coef_\n",
    "vars_df_en      = pd.DataFrame( {'Var': X_train.columns, 'Coefficient': coefficients } )\n",
    "vars_df_en      = vars_df_en.reindex( vars_df_en[ 'Coefficient' ].abs().sort_values( ascending = False ).index )\n",
    "vars_df_en.to_excel( f'../../../output/3_Regression/h19_test_final/coef_en_h19.xlsx' )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c381f705-616b-4d2e-9b8d-379582d3e141",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "y_pred = en_model.predict( X_test )\n",
    "y_pred = pd.Series(y_pred, index = y_test.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "887cb222-be0b-4cfc-9fcf-b64554938d57",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "results_en = pd.concat([y_pred, y_test],axis=1)\n",
    "results_en.rename(columns={'CPI': 'Actual', 0: 'Predicted'}, inplace=True)\n",
    "results_en"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7237cf8b-990a-4b5e-a396-a384ae6c41db",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "RMSE_en, MAPE_en = get_metrics(results_en, 'EN')\n",
    "pd.concat([RMSE_rw, RMSE_lasso, RMSE_ridge, RMSE_en], axis=1).plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fee886d8-85c7-44ee-924a-90204c7d8f24",
   "metadata": {},
   "source": [
    "### 3.2.4 Least Angle Regression (LARS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "464dd6b2-0f22-49b3-a3e3-55cf01ad31e7",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "target = \"CPI\"\n",
    "Y = pd.DataFrame(df_lags[target])\n",
    "X = df_lags.drop(columns=[target])\n",
    "\n",
    "train_set = df_lags[df_lags.index < '2019-01-01']\n",
    "test_set  = df_lags[df_lags.index >= '2019-01-01']\n",
    "\n",
    "y_train = train_set[target]\n",
    "y_test  = test_set[target]\n",
    "X_train = train_set.loc[:, train_set.columns != target]\n",
    "X_test  = test_set.loc[:, test_set.columns != target]\n",
    "\n",
    "# We define the model\n",
    "scaler = StandardScaler()\n",
    "\n",
    "# Define model\n",
    "model = Pipeline([\n",
    "    ('scaler', scaler),\n",
    "    ('regressor', Lars())  \n",
    "])\n",
    "\n",
    "# Define grid search\n",
    "grid_params_lars = {\n",
    "    'regressor__n_nonzero_coefs': np.arange(1, X.shape[1] + 1)  # Probando diferentes n√∫meros de coeficientes no nulos\n",
    "}\n",
    "\n",
    "# We implement the gridsearch\n",
    "grid_search = GridSearchCV( model, grid_params_lars, cv = tscv, scoring = 'neg_mean_squared_error')\n",
    "grid_search.fit( X_train, y_train )\n",
    "grid_search_lars = pd.DataFrame( grid_search.cv_results_ )\n",
    "\n",
    "lars_model  = grid_search.best_estimator_\n",
    "lars_params = grid_search.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21078b6b-e653-4b9a-b9ed-3863fc0089a3",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "pred_vars = X_train.columns.to_list()\n",
    "coefficients = lars_model.named_steps['regressor'].coef_\n",
    "vars_df_lars      = pd.DataFrame( {'Var': X_train.columns, 'Coefficient': coefficients } )\n",
    "vars_df_lars      = vars_df_lars.reindex( vars_df_lars[ 'Coefficient' ].abs().sort_values( ascending = False ).index )\n",
    "vars_df_lars.to_excel( f'../../../output/3_Regression/h19_test_final/coef_lars_h19.xlsx' )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4b713f8-1fd6-4598-bd0c-51bfa29b8614",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "y_pred = lars_model.predict( X_test )\n",
    "y_pred = pd.Series(y_pred, index = y_test.index)\n",
    "results_lars = pd.concat([y_pred, y_test],axis=1)\n",
    "results_lars.rename(columns={'CPI': 'Actual', 0: 'Predicted'}, inplace=True)\n",
    "results_lars"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ebb34503-3105-4429-9f4a-5286bed7ff7c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "RMSE_lars, MAPE_lars = get_metrics(results_lars, 'LARS')\n",
    "pd.concat([RMSE_rw, RMSE_lasso, RMSE_ridge, RMSE_en, RMSE_lars], axis=1).plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a415e14-1d61-4fc0-8c1f-7f9acd8e1af4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "94543f3e-f22b-4c2e-b7ba-e9aa23053738",
   "metadata": {},
   "source": [
    "### 3.2.5 Random Forest Regression (Random Forest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ce4eae0-9e82-429f-a8fb-7f9ea601b80f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "target = \"CPI\"\n",
    "Y = pd.DataFrame(df_lags[target])\n",
    "X = df_lags.drop(columns=[target])\n",
    "\n",
    "train_set = df_lags[df_lags.index < '2019-01-01']\n",
    "test_set  = df_lags[df_lags.index >= '2019-01-01']\n",
    "\n",
    "y_train = train_set[target]\n",
    "y_test  = test_set[target]\n",
    "X_train = train_set.loc[:, train_set.columns != target]\n",
    "X_test  = test_set.loc[:, test_set.columns != target]\n",
    "\n",
    "# Implementing the temporal cross-validation\n",
    "tscv = TimeSeriesSplit(n_splits=5, test_size= 12)\n",
    "\n",
    "# We implement the model\n",
    "scaler = StandardScaler()\n",
    "\n",
    "# Define model\n",
    "model = Pipeline([\n",
    "    ('scaler', scaler),\n",
    "    ('regressor', RandomForestRegressor())  \n",
    "])\n",
    "\n",
    "\n",
    "# Define grid search\n",
    "grid_params_rf = {\n",
    "    'regressor__n_estimators': [100, 200, 500],\n",
    "    'regressor__max_depth': [10, 20, 30, 50],\n",
    "    'regressor__min_samples_split': [None, 2, 5, 10],\n",
    "    'regressor__min_samples_leaf': [None, 1, 2, 4],\n",
    "    'regressor__max_features': ['auto', 'sqrt', 'log2']\n",
    "}\n",
    "\n",
    "\n",
    "# We implement the gridsearch\n",
    "grid_search = GridSearchCV( model, grid_params_rf, cv = tscv, scoring = 'neg_mean_squared_error')\n",
    "grid_search.fit( X_train, y_train )\n",
    "pd.DataFrame( grid_search.cv_results_ )\n",
    "\n",
    "rf_model  = grid_search.best_estimator_\n",
    "rf_params = grid_search.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca83654d-057a-4477-9555-866e95827cdc",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "pred_vars = X_train.columns.to_list()\n",
    "feature_importances = rf_model.named_steps['regressor'].feature_importances_\n",
    "vars_df_rf             = pd.DataFrame( {'Var': pred_vars, 'Importance Score': feature_importances } )\n",
    "vars_df_rf             = vars_df_rf.reindex(vars_df_rf[ 'Importance Score' ].abs().sort_values( ascending = False ).index )\n",
    "vars_df_rf.to_excel( f'../../../output/3_Regression/h19_test_final/coef_rf_h19.xlsx' )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0539a397-4fc2-4952-8fc1-4b60b9664da1",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "y_pred = rf_model.predict( X_test )\n",
    "y_pred = pd.Series(y_pred, index = y_test.index)\n",
    "results_rf = pd.concat([y_pred, y_test],axis=1)\n",
    "results_rf.rename(columns={'CPI': 'Actual', 0: 'Predicted'}, inplace=True)\n",
    "results_rf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab144339-b93b-4da9-9cc4-ea178aa9ef94",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "RMSE_rf, MAPE_rf = get_metrics(results_rf, 'RF')\n",
    "pd.concat([RMSE_rw, RMSE_lasso, RMSE_ridge, RMSE_en, RMSE_lars, RMSE_rf], axis=1).plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "557252f7-75f3-4efc-840b-d58a0bb0f85b",
   "metadata": {},
   "source": [
    "### 3.2.5 Support Vector Machine (SVM)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e08fa3a7-f02b-406c-a3a3-f68ddeedf1ab",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "target = \"CPI\"\n",
    "Y = pd.DataFrame(df_lags[target])\n",
    "X = df_lags.drop(columns=[target])\n",
    "\n",
    "train_set = df_lags[df_lags.index < '2019-01-01']\n",
    "test_set  = df_lags[df_lags.index >= '2019-01-01']\n",
    "\n",
    "y_train = train_set[target]\n",
    "y_test  = test_set[target]\n",
    "X_train = train_set.loc[:, train_set.columns != target]\n",
    "X_test  = test_set.loc[:, test_set.columns != target]\n",
    "\n",
    "# Implementing the temporal cross-validation\n",
    "tscv = TimeSeriesSplit(n_splits=5, test_size= 12)\n",
    "\n",
    "# We implement the model\n",
    "scaler = StandardScaler()\n",
    "svm = SVR()\n",
    "model = Pipeline([\n",
    "    ('scaler', scaler),\n",
    "    ('svm', svm)\n",
    "])\n",
    "\n",
    "# Define grid search\n",
    "param_grid_svm = {\n",
    "    'svm__C': [0.1, 1, 10, 100],\n",
    "    'svm__gamma': ['scale', 'auto'],\n",
    "    'svm__kernel': ['rbf', 'linear']\n",
    "}\n",
    "\n",
    "# We implement the gridsearch\n",
    "grid_search = GridSearchCV( model, param_grid_svm, cv = tscv, scoring = 'neg_mean_squared_error')\n",
    "grid_search.fit( X_train, y_train )\n",
    "grid_search_svm = pd.DataFrame( grid_search.cv_results_ )\n",
    "\n",
    "svm_model  = grid_search.best_estimator_\n",
    "svm_params = grid_search.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ff71750-e8df-43cf-ad72-eec8ff0877aa",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "y_pred = svm_model.predict( X_test )\n",
    "y_pred = pd.Series(y_pred, index = y_test.index)\n",
    "results_svm = pd.concat([y_pred, y_test],axis=1)\n",
    "results_svm.rename(columns={'CPI': 'Actual', 0: 'Predicted'}, inplace=True)\n",
    "results_svm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "474ab334-61bd-4489-b54e-a18c18442079",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "RMSE_svm, MAPE_svm = get_metrics(results_svm, 'SVM')\n",
    "pd.concat([RMSE_rw, RMSE_var, RMSE_lasso, RMSE_ridge, RMSE_en, RMSE_lars, RMSE_rf, RMSE_svm], axis=1).plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28b3841d",
   "metadata": {},
   "source": [
    "### 3.2.5 Random Forest Regression (Random Forest) using RandomizedCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4705f6c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "target = \"CPI\"\n",
    "Y = pd.DataFrame(df_lags[target])\n",
    "X = df_lags.drop(columns=[target])\n",
    "\n",
    "train_set = df_lags[df_lags.index < '2019-01-01']\n",
    "test_set  = df_lags[df_lags.index >= '2019-01-01']\n",
    "\n",
    "y_train = train_set[target]\n",
    "y_test  = test_set[target]\n",
    "X_train = train_set.loc[:, train_set.columns != target]\n",
    "X_test  = test_set.loc[:, test_set.columns != target]\n",
    "\n",
    "# Implementing the temporal cross-validation\n",
    "tscv = TimeSeriesSplit(n_splits=5, test_size= 12)\n",
    "\n",
    "# We implement the model\n",
    "scaler = StandardScaler()\n",
    "\n",
    "# Define model\n",
    "model = Pipeline([\n",
    "    ('scaler', scaler),\n",
    "    ('regressor', RandomForestRegressor())  \n",
    "])\n",
    "\n",
    "# Define the pipeline with the reduced set of features\n",
    "model_reduced = Pipeline([\n",
    "    ('scaler', scaler),\n",
    "    ('regressor', RandomForestRegressor())\n",
    "])\n",
    "\n",
    "# Define grid search\n",
    "grid_params_rf = {\n",
    "    'regressor__n_estimators': [100, 200, 500, 1000],\n",
    "    'regressor__max_depth': [None, 10, 20, 30, 50],\n",
    "    'regressor__min_samples_split': [None, 2, 5, 10],\n",
    "    'regressor__min_samples_leaf': [None, 1, 2, 4],\n",
    "    'regressor__max_features': ['auto', 'sqrt', 'log2']\n",
    "}\n",
    "\n",
    "\n",
    "# We implement the gridsearch\n",
    "grid_search = RandomizedSearchCV( model_reduced, grid_params_rf, cv = tscv, scoring = 'neg_mean_squared_error', n_iter=1000)\n",
    "grid_search.fit( X_train, y_train )\n",
    "pd.DataFrame( grid_search.cv_results_ )\n",
    "\n",
    "rf_model_random  = grid_search.best_estimator_\n",
    "rf_params_random = grid_search.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f76719b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# pred_vars = X_train.columns.to_list()\n",
    "# feature_importances = rf_model_random.feature_importances_\n",
    "# vars_df_rf             = pd.DataFrame( {'Var': pred_vars, 'Importance Score': feature_importances } )\n",
    "# vars_df_rf             = vars_df_rf.reindex(vars_df_rf[ 'Importance Score' ].abs().sort_values( ascending = False ).index )\n",
    "# vars_df_rf.to_excel( f'../../../output/3_Regression/h23_test/coef_rf_h23_random.xlsx' )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6e4f45a",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = rf_model_random.predict( X_test )\n",
    "y_pred = pd.Series(y_pred, index = y_test.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6cac6e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "results_rf_random = pd.concat([y_pred, y_test],axis=1)\n",
    "results_rf_random.rename(columns={'CPI': 'Actual', 0: 'Predicted'}, inplace=True)\n",
    "results_rf_random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d883d164",
   "metadata": {},
   "outputs": [],
   "source": [
    "RMSE_rf_random, MAPE_rf_random = get_metrics(results_rf_random, 'RF_Random')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b420ee30-3c40-43fb-99fa-47e8bc045e53",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "pd.concat([RMSE_rw, RMSE_var, RMSE_lasso, RMSE_rf, RMSE_rf_random, RMSE_ridge], axis=1).plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81dcd7c4-deed-4ad9-9801-fc0a7c0c2dda",
   "metadata": {},
   "source": [
    "### 3.2.4 Random Forest Regression (Random Forest) using BayesSearchCV"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dac43b5c-aade-46d1-b07f-ac65ec63f185",
   "metadata": {},
   "source": [
    "This version fits the model with the hyperparameters found in the gridsearch, then predicts with the fitted model. Same results as 3.2.3 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c21c0e02-6ec8-4eb3-87a0-df8d3e0e2ec4",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "target = \"CPI\"\n",
    "Y = pd.DataFrame(df_lags[target])\n",
    "X = df_lags.drop(columns=[target])\n",
    "\n",
    "train_set = df_lags[df_lags.index < '2019-01-01']\n",
    "test_set  = df_lags[df_lags.index >= '2019-01-01']\n",
    "\n",
    "y_train = train_set[target]\n",
    "y_test  = test_set[target]\n",
    "X_train = train_set.loc[:, train_set.columns != target]\n",
    "X_test  = test_set.loc[:, test_set.columns != target]\n",
    "\n",
    "# Implementing the temporal cross-validation\n",
    "from sklearn.model_selection import TimeSeriesSplit\n",
    "tscv = TimeSeriesSplit(n_splits=5, test_size= 12)\n",
    "\n",
    "# We implement the model\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "random_forest = RandomForestRegressor()\n",
    "model = random_forest\n",
    "\n",
    "param_space = {\n",
    "    'n_estimators': Integer(100, 500),\n",
    "    'max_features': Real(0.1, 0.9, prior='uniform'),\n",
    "    'max_depth': Integer(10, 50),\n",
    "    'min_samples_split': Integer(2, 16),\n",
    "    'min_samples_leaf': Integer(1, 6)\n",
    "}\n",
    "\n",
    "opt = BayesSearchCV(\n",
    "    estimator=model,\n",
    "    search_spaces=param_space,\n",
    "    n_iter=1000,  \n",
    "    cv=tscv,\n",
    "    scoring='neg_mean_squared_error',\n",
    "    n_jobs=-1,\n",
    "    verbose=2)\n",
    "\n",
    "opt.fit( X_train, y_train )\n",
    "\n",
    "#pd.DataFrame( grid_search.cv_results_ )\n",
    "\n",
    "# And select out best model\n",
    "rf_model_bayes  = opt.best_estimator_\n",
    "rf_params_bayes = opt.best_params_\n",
    "rf_score_bayes = opt.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e34a400-b1bc-4017-a6ab-edd621495d4e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# pred_vars = X_train.columns.to_list()\n",
    "# feature_importances = rf_model_bayes.feature_importances_\n",
    "# vars_df_rf             = pd.DataFrame( {'Var': pred_vars, 'Importance Score': feature_importances } )\n",
    "# vars_df_rf             = vars_df_rf.reindex(vars_df_rf[ 'Importance Score' ].abs().sort_values( ascending = False ).index )\n",
    "# vars_df_rf.to_excel( f'../../../output/3_Regression/h23_test/coef_rf_bayes.xlsx' )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0beb326c-5819-49ad-9c09-407c5e8d6507",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "y_pred = rf_model_bayes.predict( X_test )\n",
    "y_pred = pd.Series(y_pred, index = y_test.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d774060c-40f6-4cfb-8f94-31d83c269422",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "results_rf_bayes = pd.concat([y_pred, y_test],axis=1)\n",
    "results_rf_bayes.rename(columns={'CPI': 'Actual', 0: 'Predicted'}, inplace=True)\n",
    "results_rf_bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17d6910a-97e1-4f8c-bd31-10b0d4a5a032",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "RMSE_rf_bayes, MAPE_rf_bayes = get_metrics(results_rf_bayes, 'RF_Bayes')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c423736-1e45-4cbc-9685-217433bd7a13",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "pd.concat([RMSE_rw, RMSE_var, RMSE_lasso, RMSE_rf, RMSE_rf_random, RMSE_rf_bayes, RMSE_ridge], axis=1).plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca2aab82",
   "metadata": {},
   "source": [
    "### 3.2.3 Random Forest Regression (Random Forest) using BayesSearchCV and categorical"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32a6724a",
   "metadata": {},
   "outputs": [],
   "source": [
    "target = \"CPI\"\n",
    "Y = pd.DataFrame(df_lags[target])\n",
    "X = df_lags.drop(columns=[target])\n",
    "\n",
    "train_set = df_lags[df_lags.index < '2019-01-01']\n",
    "test_set  = df_lags[df_lags.index >= '2019-01-01']\n",
    "\n",
    "y_train = train_set[target]\n",
    "y_test  = test_set[target]\n",
    "X_train = train_set.loc[:, train_set.columns != target]\n",
    "X_test  = test_set.loc[:, test_set.columns != target]\n",
    "\n",
    "# Implementing the temporal cross-validation\n",
    "from sklearn.model_selection import TimeSeriesSplit\n",
    "tscv = TimeSeriesSplit(n_splits=5, test_size= 12)\n",
    "\n",
    "# We implement the model\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "random_forest = RandomForestRegressor()\n",
    "model = random_forest\n",
    "\n",
    "param_space = {\n",
    "    'n_estimators': Integer(100, 500),\n",
    "    'max_features': Categorical([0.1, 0.2, 0.3, 0.4, 0.5, 'log2', 'sqrt']),\n",
    "    'max_depth': Integer(10, 50),\n",
    "    'min_samples_split': Integer(2, 16),\n",
    "    'min_samples_leaf': Integer(1, 6)\n",
    "}\n",
    "\n",
    "opt = BayesSearchCV(\n",
    "    estimator=model,\n",
    "    search_spaces=param_space,\n",
    "    n_iter=1000,  \n",
    "    cv=tscv,\n",
    "    scoring='neg_mean_squared_error',\n",
    "    n_jobs=-1,\n",
    "    verbose=2)\n",
    "\n",
    "opt.fit( X_train, y_train )\n",
    "\n",
    "#pd.DataFrame( grid_search.cv_results_ )\n",
    "\n",
    "# And select out best model\n",
    "rf_model_bayes_2  = opt.best_estimator_\n",
    "rf_params_bayes_2 = opt.best_params_\n",
    "rf_score_bayes_2 = opt.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "410625ad",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "y_pred = rf_model_bayes_2.predict( X_test )\n",
    "y_pred = pd.Series(y_pred, index = y_test.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae9a6815-6117-4ab1-8000-d5622a70d41b",
   "metadata": {},
   "outputs": [],
   "source": [
    "results_rf_bayes_2 = pd.concat([y_pred, y_test],axis=1)\n",
    "results_rf_bayes_2.rename(columns={'CPI': 'Actual', 0: 'Predicted'}, inplace=True)\n",
    "results_rf_bayes_2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5466c3d3-f29a-405a-9349-bad1d06831b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "RMSE_rf_bayes_2, MAPE_rf_bayes_2 = get_metrics(results_rf_bayes_2, 'RF_Bayes_2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bdca5efe-724d-4d8b-937c-1513d4f86662",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.concat([RMSE_rw, RMSE_var, RMSE_lasso, RMSE_ridge, RMSE_rf, RMSE_rf_random, RMSE_rf_bayes, RMSE_rf_bayes_2], axis=1).plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d53eddb0",
   "metadata": {},
   "source": [
    "## 3.3 Results\n",
    "Here we concat all results into a single dataframe. We export the table to excel.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8186ee53",
   "metadata": {},
   "source": [
    "### 3.3.1 General results\n",
    "Here we will create graphs and tables with the results of all models combined into a single datagrame."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7fcfdcb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "RMSE_2023 = pd.concat([RMSE_rw, RMSE_var, RMSE_lasso, RMSE_ridge, RMSE_en, RMSE_lars, RMSE_rf, RMSE_rf_bayes, RMSE_rf_bayes_2, RMSE_svm], axis=1)\n",
    "MAPE_2023 = pd.concat([MAPE_rw, MAPE_var, MAPE_lasso, MAPE_ridge, MAPE_en, MAPE_lars, MAPE_rf, MAPE_rf_bayes, MAPE_rf_bayes_2, MAPE_svm], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a76c1d91-c8d0-40da-9907-01666eb861ac",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "RMSE_2023"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe3e9c00",
   "metadata": {},
   "outputs": [],
   "source": [
    "RMSE_2023.plot(label=colors)\n",
    "\n",
    "plt.xlabel('Horizons')\n",
    "plt.ylabel('RMSE')\n",
    "plt.title('RMSE of different models for 2023')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8074158",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "RMSE_2023_results = RMSE_2023.div(RMSE_rw['RMSE_RW'], axis=0)\n",
    "# RMSE_2023_results = RMSE_2023_results.drop(columns=['RMSE_RW'])\n",
    "RMSE_2023_results_highlight = RMSE_2023_results.style.apply(highlight_min, axis=1)\n",
    "RMSE_2023_results_highlight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0bbc10b",
   "metadata": {},
   "outputs": [],
   "source": [
    "MAPE_2023_results = MAPE_2023.div(MAPE_rw['MAPE_RW'], axis=0)\n",
    "# MAPE_2023_results = MAPE_2023_results.drop(columns=['MAPE_RW'])\n",
    "MAPE_2023_results_highlight = MAPE_2023_results.style.apply(highlight_min, axis=1)\n",
    "MAPE_2023_results_highlight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d198a6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "tableH23 = RMSE_2023_results\n",
    "tableH23 = tableH23.rename(columns = {'RMSE_RW': 'RW', 'RMSE_VAR': 'VAR', 'RMSE_Ridge': 'Ridge', 'RMSE_EN':'Elastic Net',\n",
    "                            'RMSE_Lasso': 'Lasso', 'RMSE_LARS':'LARS', 'RMSE_RF':'RF', 'RMSE_RF_Random':'RF_Random', 'RMSE_RF_Bayes':'RF_Bayes', 'RMSE_RF_Bayes_2':'RF_Bayes_2', 'RMSE_SVM':'SVM'})\n",
    "tableH23.index.name = 'horizon'\n",
    "tableH23.to_excel(\"../../../output/3_Regression/h23_test/table_rmse_h23.xlsx\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95851a1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "tableH23 = MAPE_2023_results\n",
    "tableH23 = tableH23.rename(columns = {'MAPE_RW': 'RW', 'MAPE_VAR': 'VAR', 'MAPE_Ridge': 'Ridge', 'MAPE_EN':'Elastic Net',\n",
    "                            'MAPE_Lasso': 'Lasso', 'MAPE_LARS':'LARS', 'MAPE_RF':'RF',  'MAPE_RF_Random':'RF_Random', 'MAPE_RF_Bayes':'RF_Bayes', 'MAPE_RF_Bayes_2':'RF_Bayes_2', 'MAPE_SVM':'SVM'})\n",
    "tableH23.index.name = 'horizon'\n",
    "tableH23.to_excel(\"../../../output/3_Regression/h23_test/table_mape_h23.xlsx\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc0326e4-7f09-4137-ad54-9b6fb94beee9",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# colors = {\n",
    "#     'RMSE_VAR': 'blue',   \n",
    "#     'RMSE_Ridge': 'green', \n",
    "#     'RMSE_Lasso': 'red',  \n",
    "#     'RMSE_RF': 'purple'   \n",
    "# }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6ab0293",
   "metadata": {},
   "outputs": [],
   "source": [
    "# graph_models(RMSE_2023_results, lim=2.5, colors=colors, path=\"../../../output/3_Regression/h19_test/h_rmse.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1c7dd42",
   "metadata": {},
   "outputs": [],
   "source": [
    "# colors = {'MAPE_VAR': 'tab:red', 'MAPE_Ridge': 'tab:brown', 'MAPE_Lasso': 'tab:purple', 'MAPE_RF': 'tab:pink'}\n",
    "\n",
    "# graph_models(MAPE_2023_results, metric = \"MAPE\", lim=1.5, colors=colors, path=\"../../../output/3_Regression/h19_test/mape.png\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f689272",
   "metadata": {},
   "source": [
    "### 3.3.2 Coefficients by model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8cfc598",
   "metadata": {},
   "outputs": [],
   "source": [
    "# graph_coefficients(vars_df_ridge, value = \"Coefficient\", path=\"../../../output/3_Regression/h19_test/coef_ridge.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18f428a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# graph_coefficients(vars_df_lasso, value = \"Coefficient\", path=\"../../../output/3_Regression/h19_test/h23_coef_lasso.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57f86b68",
   "metadata": {},
   "outputs": [],
   "source": [
    "# graph_coefficients(vars_df_rf, value = \"Importance Score\", path=\"../../../output/3_Regression/h19_test/coef_rf.png\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7df3f6eb-28f0-4946-b514-5ce09c1db87a",
   "metadata": {},
   "source": [
    "### 3.3.3 Prediction plots\n",
    "We are going to plot our predictions in a single plot to compare visually how different models performed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "357e0b21-347e-4d17-8834-e90ca56c5a7f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "y_train['2014':].plot(label=None)\n",
    "df['CPI']['2018-12-01':].plot(label='Actual')\n",
    "results_rw['Predicted'].plot(label='RW')\n",
    "results_var['Predicted'].plot(label='VAR')\n",
    "results_lasso['Predicted'].plot(label='Lasso')\n",
    "results_ridge['Predicted'].plot(label='Ridge')\n",
    "results_en['Predicted'].plot(label='EN')\n",
    "results_rf['Predicted'].plot(label='RF')\n",
    "results_rf_random['Predicted'].plot(label='RF_Random')\n",
    "results_rf_bayes['Predicted'].plot(label='RF_Bayes')\n",
    "results_rf_bayes_2['Predicted'].plot(label='RF_Bayes_2')\n",
    "results_svm['Predicted'].plot(label='SVM')\n",
    "\n",
    "plt.legend()\n",
    "\n",
    "#plt.title('Comparison of models predictions for 2023')\n",
    "plt.xlabel('Year')\n",
    "plt.ylabel('CPI')\n",
    "\n",
    "plt.savefig('../../../output/3_Regression/h23_test/model_final.png', bbox_inches='tight', dpi=300)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dbd8bd17-389e-4944-af79-7469e59f9c27",
   "metadata": {},
   "source": [
    "### 3.3.4 Dielbold-Mariano test\n",
    "We implement the diebold-mariano test to see if the different in forecasts is statistically significant."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61d3c706-8938-4c40-90e6-e7ccea3e2055",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# # RW - VAR\n",
    "# print('DM test for VAR:', dm_test(results_rw['Actual'], results_rw['Predicted'], results_var['Predicted'],  h = 3, crit=\"MSE\"))\n",
    "\n",
    "# # RW - Ridge\n",
    "# print('DM test for Ridge: ', dm_test(results_rw['Actual'], results_rw['Predicted'], results_ridge['Predicted'],  h = 3, crit=\"MSE\"))\n",
    "\n",
    "# # RW - Lasso\n",
    "# print('DM test for Lasso: ', dm_test(results_rw['Actual'], results_rw['Predicted'], results_lasso['Predicted'],  h = 3, crit=\"MSE\"))\n",
    "\n",
    "# # RW - RF\n",
    "# print('DM test for RF: ', dm_test(results_rw['Actual'], results_rw['Predicted'], results_rf['Predicted'],  h = 3, crit=\"MSE\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52fc6729-7641-4d20-aa7d-fe2a28866370",
   "metadata": {},
   "source": [
    "We conclude that:\n",
    "- The RW appears to be better than the VAR, but it is not statiscally significant\n",
    "- While the RW appers to have worse forecast predictions than the ML models, it is not statistically outperformed by the other models."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30b8fd47-43a1-4fd6-91f4-038ae72a3580",
   "metadata": {},
   "source": [
    "## 3.3.5 Best parameters\n",
    "We here print the best parameters the Gridsearch selected for each model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33b69499-4995-44f0-94b4-1cbe95525bb6",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "print(lasso_params)\n",
    "print(ridge_params)\n",
    "print(rf_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9909fec3-529f-43df-a3dc-57d4fbc67ed9",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(rf_params_random)\n",
    "print(rf_params_bayes)\n",
    "print(rf_params_bayes_2)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
